{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2f8d240",
   "metadata": {
    "id": "b2f8d240"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/drive/1OYipLzeOxvKYPBtOtRfyRn2lFV76lrZM\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "# FiftyOne Workshop - Agriculture\n",
    "# Coffee Dataset Exploration -> Geolocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c693a61",
   "metadata": {
    "id": "8c693a61"
   },
   "source": [
    "## ðŸ† Learning Objectives\n",
    "- Understand how to load and explore a dataset using FiftyOne.\n",
    "- Perform basic dataset inspection and visualization.\n",
    "- Explore geolocation data (if available) in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78faca9f",
   "metadata": {
    "id": "78faca9f"
   },
   "source": [
    "## Requirements\n",
    "### Knowledge\n",
    "- Basic Python programming.\n",
    "- Familiarity with Computer Vision concepts.\n",
    "- Understanding of geospatial data (optional).\n",
    "### Installation\n",
    "Run the following command to install necessary dependencies:\n",
    "```bash\n",
    "pip install --upgrade pip\n",
    "pip install fiftyone\n",
    "pip install \"huggingface_hub>=0.20.0\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lJhn8YVDaP7g",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13209,
     "status": "ok",
     "timestamp": 1754070508182,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "lJhn8YVDaP7g",
    "outputId": "178f192d-d4e6-4d03-fa7b-dc6db87a227b"
   },
   "outputs": [],
   "source": [
    "!pip install fiftyone\n",
    "!pip install \"huggingface_hub>=0.20.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nJV1lOk6hYap",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2948,
     "status": "ok",
     "timestamp": 1754070517712,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "nJV1lOk6hYap",
    "outputId": "23948a87-7e49-4bbd-f5e8-a1901b93becb"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Get the appropriate device for model inference.\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif hasattr(torch.backends, \"mps\") and torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cpu\"\n",
    "\n",
    "DEVICE = get_device()\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "G1iznXJuq9eM",
   "metadata": {
    "id": "G1iznXJuq9eM"
   },
   "source": [
    "## Load a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GPF3PmLIq9eM",
   "metadata": {
    "id": "GPF3PmLIq9eM"
   },
   "source": [
    "Let's get started by importing the FiftyOne library, and the utils we need for a COCO format dataset, depending of the dataset format you should change that option. [Supported Formats](https://docs.voxel51.com/user_guide/dataset_creation/datasets.html#supported-formats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zc4ExXxiq9eM",
   "metadata": {
    "executionInfo": {
     "elapsed": 3335,
     "status": "ok",
     "timestamp": 1754070524519,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "Zc4ExXxiq9eM"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.utils.huggingface as fouh\n",
    "from fiftyone.utils.coco import COCODetectionDatasetImporter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nNBf3p3-boOM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "executionInfo": {
     "elapsed": 13216,
     "status": "ok",
     "timestamp": 1754070539661,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "nNBf3p3-boOM",
    "outputId": "14e60fcf-e747-4e04-9930-70ea9372f2b4"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Download the coffee dataset from Google Drive\n",
    "\n",
    "url = \"https://drive.google.com/uc?id=1TMeeIzj8EyocVyXmOgKSLYE3vTLc2gPe\" # original\n",
    "gdown.download(url, output=\"coffee_original.zip\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SIKCv4Y3hVHe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10721,
     "status": "ok",
     "timestamp": 1754070551990,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "SIKCv4Y3hVHe",
    "outputId": "1f8b38cd-c0fd-4d5e-c986-170e7496e444"
   },
   "outputs": [],
   "source": [
    "!unzip coffee_original.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6i1spCQhalQe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "executionInfo": {
     "elapsed": 3205,
     "status": "ok",
     "timestamp": 1754070706865,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "6i1spCQhalQe",
    "outputId": "643538ac-3662-4b88-db65-d75a74ed20b2"
   },
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Download the CarDD dataset from Google Drive\n",
    "url = \"https://drive.google.com/uc?id=1YHBdFd5SJuiqRK4YV6pJr4-6p4_830lE\"\n",
    "gdown.download(url, output=\"Coffee_Tree_Geolocations.csv\", quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac9faaf",
   "metadata": {
    "id": "0ac9faaf"
   },
   "source": [
    "## 1. Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79079143",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14743,
     "status": "ok",
     "timestamp": 1754070755594,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "79079143",
    "outputId": "35526b12-9e45-4593-d66f-90a0200e3187"
   },
   "outputs": [],
   "source": [
    "# import fiftyone as fo # base library and app\n",
    "# import fiftyone.utils.huggingface as fouh # Hugging Face integration\n",
    "# dataset_ = fouh.load_from_hub(\"pjramg/my_colombian_coffe_FO\", persistent=True, overwrite=True)\n",
    "\n",
    "# # Define the new dataset name\n",
    "dataset_name = \"coffee_original\"\n",
    "\n",
    "# Check if the dataset exists\n",
    "if dataset_name in fo.list_datasets():\n",
    "    print(f\"Dataset '{dataset_name}' exists. Loading...\")\n",
    "    dataset = fo.load_dataset(dataset_name)\n",
    "else:\n",
    "    print(f\"Dataset '{dataset_name}' does not exist. Creating a new one...\")\n",
    "    # Clone the dataset with a new name and make it persistent\n",
    "    dataset = fo.Dataset.from_dir(\n",
    "                dataset_type=fo.types.COCODetectionDataset,\n",
    "                dataset_dir=\"./colombian_coffee\",\n",
    "                data_path=\"images/default\",\n",
    "                labels_path=\"annotations/instances_default.json\",\n",
    "                label_types=\"segmentations\",\n",
    "                label_field=\"categories\",\n",
    "                name=\"coffee\",\n",
    "                include_id=True,\n",
    "                overwrite=True\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26822fde",
   "metadata": {
    "id": "26822fde"
   },
   "source": [
    "## 2. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff5fc07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 7938,
     "status": "ok",
     "timestamp": 1754070888746,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "7ff5fc07",
    "outputId": "161e2dde-5373-4950-8302-88b523e6e853"
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef77c3b",
   "metadata": {
    "id": "eef77c3b"
   },
   "source": [
    "## 3. Geolocation Analysis\n",
    "If the dataset contains geolocation metadata, use FiftyOneâ€™s visualization tools to inspect it. Download the ```csv``` file within this repo folder. ```\"Coffee_Tree_Geolocations.csv\"```. Change the location in the csv_file if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88948de7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5712,
     "status": "ok",
     "timestamp": 1754070934382,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "88948de7",
    "outputId": "d8de4eed-dd35-4a51-b8ce-f12116b9c2f8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "# Load the CSV file with tree geolocations\n",
    "csv_file = \"Coffee_Tree_Geolocations.csv\"  # Update with the correct file path\n",
    "tree_data = pd.read_csv(csv_file)\n",
    "\n",
    "# Shuffle geolocations to assign randomly\n",
    "tree_data = tree_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Assign geolocations to samples\n",
    "for sample, (_, row) in zip(dataset, tree_data.iterrows()):\n",
    "    sample[\"location\"] = fo.GeoLocation(\n",
    "        point=[row[\"longitude\"], row[\"latitude\"]]\n",
    "    )\n",
    "    sample.save()\n",
    "\n",
    "print(\"Geolocation metadata assigned successfully!\")\n",
    "\n",
    "# Verify the first few samples\n",
    "print(dataset.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba998f91",
   "metadata": {
    "id": "ba998f91"
   },
   "source": [
    "## 4. Analyzing Maturation States in the Dataset\n",
    "To gain more insights into the dataset, we analyze the segmentation results by categorizing coffee beans into different maturation stages.\n",
    "This helps in understanding the distribution of different maturation states across the dataset.\n",
    "\n",
    "### Steps in the Analysis:\n",
    "- **Load the dataset** and ensure segmentations are available.\n",
    "- **Count occurrences of different maturation states** based on segmentation labels.\n",
    "- **Assign explicit numerical values** to facilitate analysis and visualization.\n",
    "- **Ensure all fields are correctly set** to avoid issues with visualization plugins.\n",
    "\n",
    "The following script processes each sample in the dataset and adds metadata fields representing:\n",
    "- The count of beans in different maturation stages.\n",
    "- The dominant maturation stage for each sample.\n",
    "- Ensuring all fields have valid values to avoid errors in visualization.\n",
    "\n",
    "### Code Implementation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b949534",
   "metadata": {
    "id": "2b949534"
   },
   "source": [
    "First we need to install The Plotly Map Panel, ```#!fiftyone plugins download https://github.com/allenleetc/plotly-map-panel```. This is a community plugin for FiftyOne that provides an alternative to the built-in Map Panel, which relies on Mapbox. This plugin utilizes PlotlyView for interactive geospatial visualizations, making it a great option for users who want a flexible, open-source alternative without requiring Mapbox API keys. Once installed, you can enable the Plotly Map Panel in the FiftyOne App by navigating to:\n",
    "\n",
    "    - Open the FiftyOne App\n",
    "    - Go to the Plugins Menu\n",
    "    - Enable \"Plotly Map Panel\"\n",
    "    - Load a dataset with geolocation metadata\n",
    "    - Start visualizing geospatial data interactively!\n",
    "\n",
    "When to Use This Plugin?\n",
    "\n",
    "    - If you need interactive maps without requiring Mapbox.\n",
    "    - When working with datasets containing latitude/longitude metadata.\n",
    "    - To compare spatial distributions of objects across locations.\n",
    "    - For customizing geospatial visualization with Plotlyâ€™s flexibility.\n",
    "\n",
    "By integrating this plugin, you can unlock geospatial insights in your FiftyOne datasets more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee051b89",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4322,
     "status": "ok",
     "timestamp": 1754070921740,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "ee051b89",
    "outputId": "f8b95f16-d0ff-49d4-b21b-7af991b6e059"
   },
   "outputs": [],
   "source": [
    "!fiftyone plugins download https://github.com/allenleetc/plotly-map-panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feff025",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4569,
     "status": "ok",
     "timestamp": 1754071163284,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "7feff025",
    "outputId": "d18d04e5-f1d9-4ab1-ecb9-62daa73df082"
   },
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "from collections import Counter\n",
    "\n",
    "# Load the existing dataset\n",
    "# dataset = fo.load_dataset(\"coffee_beans_dataset\")  # Replace with your dataset name\n",
    "\n",
    "# Define label-to-index mapping\n",
    "label_mapping = {\n",
    "    \"immature\": 1,\n",
    "    \"semimature\": 2,\n",
    "    \"mature\": 3,\n",
    "    \"overmature\": 4,\n",
    "}\n",
    "\n",
    "# Iterate over each sample\n",
    "for sample in dataset:\n",
    "    # Ensure the \"categories_segmentations\" field exists and contains detections\n",
    "    detections = getattr(sample, \"categories_segmentations\", None)\n",
    "    if detections and hasattr(detections, \"detections\"):\n",
    "        detections = detections.detections\n",
    "    else:\n",
    "        detections = []\n",
    "\n",
    "    # Count occurrences of each maturation state\n",
    "    label_counts = Counter(d.label for d in detections if d.label is not None)\n",
    "\n",
    "    # Explicitly set count fields, ensuring no `None` values\n",
    "    sample[\"immature_count\"] = int(label_counts.get(\"immature\", 0))\n",
    "    sample[\"mature_count\"] = int(label_counts.get(\"mature\", 0))\n",
    "    sample[\"semimature_count\"] = int(label_counts.get(\"semimature\", 0))\n",
    "    sample[\"overmature_count\"] = int(label_counts.get(\"overmature\", 0))\n",
    "\n",
    "    # Determine the maturation stage with the highest count\n",
    "    if label_counts:\n",
    "        max_label, max_count = max(label_counts.items(), key=lambda x: x[1])\n",
    "    else:\n",
    "        max_label, max_count = \"unknown\", 0  # Avoid NoneType errors\n",
    "\n",
    "    # Assign segmentation status (1 = No segmentations, 0 = Has segmentations)\n",
    "    sample[\"No_Segmentations\"] = 1 if max_count == 0 else 0\n",
    "\n",
    "    # Ensure numeric fields for compatibility with visualization\n",
    "    sample[\"max_maturation_count\"] = int(max_count) if max_count > 0 else 0\n",
    "    sample[\"max_maturation_stage\"] = int(label_mapping.get(max_label, 0)) if max_count > 0 else 0\n",
    "    sample[\"max_maturation_count_str\"] = str(max_count) if max_count > 0 else \"0\"\n",
    "\n",
    "    # Save the updated metadata\n",
    "    sample.save()\n",
    "\n",
    "print(\"Maturation state metadata added successfully!\")\n",
    "\n",
    "# Verify the first sample\n",
    "print(dataset.first())  # Print a sample to confirm\n",
    "print(dataset)  # Print the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cKxyCfstV6m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1754069961146,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "2cKxyCfstV6m",
    "outputId": "16389f42-485e-4d85-c81f-e706f3550678"
   },
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n",
    "session.open_tab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lpRWQMeat2Gf",
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1754069957439,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "lpRWQMeat2Gf"
   },
   "outputs": [],
   "source": [
    " session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93908b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1754071594695,
     "user": {
      "displayName": "Paula Ramos",
      "userId": "16781678718580955474"
     },
     "user_tz": 240
    },
    "id": "c93908b9",
    "outputId": "6528b16f-c720-4327-f2e5-337fa0214e44"
   },
   "outputs": [],
   "source": [
    "# Create a view that filters samples with No_Segmentations = 0\n",
    "segmented_view = dataset.match({\"No_Segmentations\": 0})\n",
    "\n",
    "# Print the number of matching samples\n",
    "print(f\"Number of segmented samples: {len(segmented_view)}\")\n",
    "\n",
    "# Launch FiftyOne App to visualize the view\n",
    "session = fo.launch_app(segmented_view, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3b36b9",
   "metadata": {
    "id": "1b3b36b9"
   },
   "source": [
    "[![ploty.png](https://i.postimg.cc/qBZnxy8p/ploty.png)](https://postimg.cc/F1379fW6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76700692",
   "metadata": {
    "id": "76700692"
   },
   "source": [
    "## Next Steps\n",
    "- Learn how to apply AI models for segmentation.\n",
    "- Use FiftyOne for annotation and active learning workflows.\n",
    "- Proceed to the SAM2 annotation notebook for object segmentation."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
